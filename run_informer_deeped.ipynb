{"cells":[{"cell_type":"markdown","metadata":{},"source":["## DeepED Informer"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# !jupyter nbconvert --to script run_informer_deeped.ipynb"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","import os\n","import time \n","import gc\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import mean_squared_error\n","\n","from utils.tools import dotdict\n","from exp.exp_informer import Exp_Informer, Exp_Informer_DeepED"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer_noT' # model of experiment, options: [informer_noT, transformer_noT]\n","# args.model = 'transformer_noT' \n","\n","args.data = 'deeped' # data\n","args.root_path = os.path.join('Dataset', 'DeepED_dataset') # root path of data file\n","args.data_path = 'res_train4_test8_v02.npz' # data file\n","args.stat_path = 'data_stats.npz' # stat file\n","args.asi = 1\n","args.aei = 3\n","\n","args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'OT' # target feature in S or MS task\n","args.freq = 'h' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 12 # [idx : idx+seq_len]: input sequence length of Informer encoder\n","args.label_len = 1 # [idx+seq_len-label_len : idx+seq_len]: start token length of Informer decoder; overlap with seq_len counting from the end of seq_len\n","args.pred_len = 1 # [idx+seq_len : idx+seq_len+pred_len]: prediction sequence length; no overlap iwth seq_len\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","args.enc_in = 136 # encoder input size\n","args.dec_in = 7 # decoder input size\n","args.c_out = 7 # output size\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 512 # dimension of model\n","args.n_heads = 8 # num of heads\n","args.e_layers = 2 # num of encoder layers\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'prob' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'h'\n","\n","args.batch_size = 32\n","args.learning_rate = 0.0001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 1\n","args.patience = 3\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0'\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["None h\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","    \n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","print(args.detrail_freq, args.freq)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["Exp = Exp_Informer_DeepED"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n"]}],"source":["ii = 0 # experiment index\n","setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_asi{}_aei{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features,\n","            args.seq_len, args.label_len, args.pred_len, args.asi, args.aei,\n","            args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","# set experiments\n","exp = Exp(args)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # debug\n","# train_data, train_loader = exp._get_data(flag = 'train')\n","# val_data, val_loader = exp._get_data(flag = 'val')\n","# test_data, test_loader = exp._get_data(flag = 'test')\n","\n","# a, b = train_data[0]\n","# print(a.shape, b.shape)\n","\n","# for i, (batch_x,batch_y) in enumerate(train_loader):\n","#   batch_x = batch_x.float().to(exp.device)\n","#   batch_y = batch_y.float()\n","  \n","#   dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n","\n","#   dec_inp = torch.cat([batch_y[:,:exp.args.label_len,:], dec_inp], dim=1).float().to(exp.device)\n","  \n","#   pred = exp.model(batch_x, dec_inp)\n","#   break"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[">>>>>>>start training : transformer_noT_deeped_ftM_sl12_ll1_pl1_asi1_aei3_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train data size x=(33280, 12, 136), y=(33280, 2, 7)\n","train 33280\n","val data size x=(3680, 12, 136), y=(3680, 2, 7)\n","val 3680\n","test data size x=(7840, 12, 136), y=(7840, 2, 7)\n","test 7840\n","\titers: 100, epoch: 1 | loss: 0.0796064\n","\tspeed: 0.0610s/iter; left time: 57.4049s\n","\titers: 200, epoch: 1 | loss: 0.0768073\n","\tspeed: 0.0127s/iter; left time: 10.6664s\n","\titers: 300, epoch: 1 | loss: 0.0867499\n","\tspeed: 0.0132s/iter; left time: 9.8106s\n","\titers: 400, epoch: 1 | loss: 0.0622987\n","\tspeed: 0.0130s/iter; left time: 8.3283s\n","\titers: 500, epoch: 1 | loss: 0.0870776\n","\tspeed: 0.0128s/iter; left time: 6.9317s\n","\titers: 600, epoch: 1 | loss: 0.0403367\n","\tspeed: 0.0128s/iter; left time: 5.6530s\n","\titers: 700, epoch: 1 | loss: 0.0435906\n","\tspeed: 0.0135s/iter; left time: 4.6042s\n","\titers: 800, epoch: 1 | loss: 0.0515782\n","\tspeed: 0.0131s/iter; left time: 3.1689s\n","\titers: 900, epoch: 1 | loss: 0.0316665\n","\tspeed: 0.0137s/iter; left time: 1.9258s\n","\titers: 1000, epoch: 1 | loss: 0.0207214\n","\tspeed: 0.0137s/iter; left time: 0.5598s\n","Epoch: 1 cost time: 17.97957444190979\n","Epoch: 1, Steps: 1040 | Train Loss: 0.0759249 Vali Loss: 0.0499668 Test Loss: 0.0460129\n","Validation loss decreased (inf --> 0.049967).  Saving model ...\n","Updating learning rate to 0.0001\n",">>>>>>>testing : transformer_noT_deeped_ftM_sl12_ll1_pl1_asi1_aei3_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test data size x=(7840, 12, 136), y=(7840, 2, 7)\n","test 7840\n","test shape: (245, 32, 1, 7) (245, 32, 1, 7)\n","test shape: (7840, 1, 7) (7840, 1, 7)\n","mse:0.04601292684674263, mae:0.12098956853151321\n"]}],"source":["# train\n","print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","exp.train(setting)\n","\n","# test             \n","print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","exp.test(setting)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# for ii in range(args.itr):\n","#     # setting record of experiments\n","#     setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features,\n","#                 args.seq_len, args.label_len, args.pred_len,\n","#                 args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","#     # set experiments\n","#     exp = Exp(args)\n","\n","#     # train\n","#     print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","#     exp.train(setting)\n","\n","#     # test\n","#     print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","#     exp.test(setting)\n","\n","#     torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{},"source":["### Prediction"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Working on age: [10]\n","  Target age: [10]\n"]}],"source":["#-- resutl output path\n","DIR_INT = os.path.join('Dataset', 'DeepED_dataset')\n","# DIR_OUT = 'results'\n","\n","# output bands\n","TREE_BAND = ['height', 'agb', 'soil', 'lai', 'gpp', 'npp', 'rh']\n","\n","\n","# parameters\n","N_T = 12 \n","N_YEAR = 40\n","N_AGE = 15\n","N_OUT = len(TREE_BAND)\n","\n","N_CONS = 136 # number of atmos features\n","N_FEA = N_CONS + N_OUT + 15 # add age info\n","\n","eval_filename = 'res_train4_test8_v02.npz'\n","agetri_filename = 'age_triplet.npz'\n","stat_filename = 'data_stats.npz'\n","\n","isDup = True\n","\n","# read stat data\n","data_stat = np.load(os.path.join(DIR_INT, stat_filename))\n","X_MEAN = data_stat['x_mean']\n","Y_MEAN = data_stat['y_mean']\n","X_STD = data_stat['x_std']\n","Y_STD = data_stat['y_std']\n","\n","# read age\n","age_triplet = np.load(os.path.join(DIR_INT, agetri_filename))\n","TRI_AGE = age_triplet['age']\n","TRI_MEAN = age_triplet['age_mean']\n","TRI_SLOPE = age_triplet['age_slope']\n","\n","age_start_idx = 1\n","age_end_idx = 2\n","\n","# select age\n","TRI_AGE = TRI_AGE[age_start_idx:age_end_idx]\n","TRI_MEAN = TRI_MEAN[age_start_idx:age_end_idx]\n","TRI_SLOPE = TRI_SLOPE[age_start_idx:age_end_idx]\n","N_AGE = TRI_AGE.size\n","print(f'Working on age: {TRI_AGE}')\n","\n","age_tri = [TRI_AGE, TRI_MEAN, TRI_SLOPE]\n","data_stat = [X_MEAN, X_STD, Y_MEAN, Y_STD]\n","\n","\n","def normData(inp, mean, std): \n","  # assert inp.shape[-1] == mean.size\n","  # assert std.size == mean.size\n","  \n","  return (inp-mean)/(std+1e-10)\n","\n","def invNormData(inp, mean, std): \n","  # assert inp.shape[-1] == mean.size\n","  # assert std.size == mean.size\n","  \n","  return inp*(std+1e-10)+mean\n","\n","def dupMonth(y, dup_idx=11):\n","  # assert dup_idx < N_T\n","  \n","  return np.repeat(y[...,dup_idx:dup_idx+1,:], N_T, axis=-2)\n","\n","def addAgeTriplet_perAge(x, np_age, np_mean, np_slope):\n","  ''' \n","  For x with all ages, add age triplet to the last dimension of x\n","    x: [N_Sample, N_YEAR, N_T, N_BAND]\n","    np_age: [1]\n","    np_mean/np_slope: [N_BAND]\n","  '''\n","  # form data structure\n","  res_mean = np.repeat(np_mean[np.newaxis], x.shape[2], axis=0)\n","  res_mean = np.repeat(res_mean[np.newaxis], x.shape[1], axis=0)\n","  res_mean = np.repeat(res_mean[np.newaxis], x.shape[0], axis=0)\n","  res_slope = np.repeat(np_slope[np.newaxis], x.shape[2], axis=0)\n","  res_slope = np.repeat(res_slope[np.newaxis], x.shape[1], axis=0)\n","  res_slope = np.repeat(res_slope[np.newaxis], x.shape[0], axis=0)\n","  \n","  res_age = np.arange(N_YEAR)[np.newaxis] + np_age\n","  res_age = np.transpose(res_age, (1,0))\n","  res_age = np.repeat(res_age[:,np.newaxis], x.shape[-2], axis=1)\n","  res_age = np.repeat(res_age[np.newaxis], x.shape[0], axis=0)\n","  \n","  # scale age\n","  res_age = res_age / 500.\n","  \n","  # concat\n","  res = np.concatenate([x, res_age.astype(np.float32)], axis=-1)\n","  res = np.concatenate([res, res_mean.astype(np.float32)], axis=-1)\n","  res = np.concatenate([res, res_slope.astype(np.float32)], axis=-1)\n","  \n","  return res\n","  \n","  \n","def addInitY2X(x, y): \n","  out = np.repeat(x[np.newaxis], y.shape[0], axis=0)\n","  return np.concatenate([out, y[:,:,:-1]], axis=-1)\n","\n","[tri_age, tri_mean, tri_slope] = age_tri\n","[x_mean, x_std, y_mean, y_std] = data_stat\n","\n","print(f'  Target age: {tri_age}')  \n","  \n","\n","def plotAge(np_rmse, TRI_AGE, isOutput=True, path_out='', y_lim=[0,3.5]):\n","  # plot age\n","  num_age = np_rmse.shape[0]\n","  ls_cor = ['r','g','b','c','y','m','k']\n","  \n","  if num_age == 1: \n","    fig_r = 1\n","    fig_c = 2\n","    figsize = (4,3)\n","    \n","    fig = plt.figure(figsize=figsize)\n","    cur_rmse = np_rmse[0]\n","    for k in range(N_OUT):\n","      plt.plot(cur_rmse[:,k], ls_cor[k], label=TREE_BAND[k])\n","    \n","    plt.ylim(y_lim)\n","    plt.title('Age'+str(TRI_AGE[0])) \n","    plt.ylabel('RMSE')\n","    # plt.set_xticks(list(range(0,32,30)))\n","    # plt.set_xticklabels(list(range(1986,2017,30)))\n","\n","    plt.legend(loc=0, prop={'size': 7})\n","\n","  else: \n","    fig_r = 3\n","    fig_c = 5\n","    figsize = (10,7)\n","    \n","    plt.figure()\n","    fig, axes = plt.subplots(fig_r, fig_c, figsize=figsize)\n","    for i in range(fig_r):\n","      for j in range(fig_c):\n","        if i*fig_c+j < num_age: \n","          cur_rmse = np_rmse[i*fig_c+j]\n","          for k in range(N_OUT):\n","            axes[i,j].plot(cur_rmse[:,k], ls_cor[k])\n","\n","          # axes[i,j].set_xticks(list(range(0,32,30)))\n","          # axes[i,j].set_xticklabels(list(range(1986,2017,30)))\n","          axes[i,j].set_ylim(y_lim)\n","          axes[i,j].set_title('Age'+str(TRI_AGE[i*fig_c+j]))\n","          \n","      axes[i,0].set_ylabel('RMSE')\n","\n","    # add legend\n","    for k in range(N_OUT):\n","      axes[i,j].plot([0], [0], ls_cor[k], label=TREE_BAND[k])\n","    axes[i,j].legend(loc=10, prop={'size': 7})   \n","    \n","  # save \n","  fig.tight_layout()\n","  if isOutput:\n","    plt.savefig(path_out+'_fig', bbox_inches='tight')\n","  print('  Plot done!\\n')      \n","\n","\n","def convertRMSE2Table(ls_rmse_all, TRI_AGE): \n","  rmse = np.transpose(ls_rmse_all, [0,2,1])\n","  pd_rmse = pd.DataFrame(rmse.reshape((-1, rmse.shape[2])))\n","  tmp = pd.DataFrame(np.repeat(TRI_AGE, N_OUT), columns=['age'])\n","  pd_rmse = pd.concat([tmp, pd_rmse], axis=1)\n","  return pd_rmse\n","\n","\n","# predict using prediction\n","def eval(emulator, path_test, path_out, age_tri, data_stat, age_used_idx, isPred2Input=True, isTrain=False, isOutput=True, isDup=True, y_lim=[0,3.5]):\n","  print('--- Start evaluation ---')\n","  \n","  [tri_age, tri_mean, tri_slope] = age_tri\n","  [x_mean, x_std, y_mean, y_std] = data_stat\n","  [age_start_idx, age_end_idx] = age_used_idx\n","  \n","  print(f'  Target age: {tri_age}')  \n","  \n","  #--- Loading data ---  \n","  data_train = np.load(path_test)\n","  if not isTrain:\n","    x_name = 'x_test'\n","    y_name = 'y_test' \n","  else: \n","    x_name = 'x_train'\n","    y_name = 'y_train'\n","\n","  x_test = normData(data_train[x_name], x_mean, x_std)\n","  y_test = normData(data_train[y_name], y_mean, y_std)\n","  \n","  y_test = y_test[age_start_idx:age_end_idx]\n","\n","  del data_train\n","  gc.collect()\n","  \n","  print(f'X shape: {x_test.shape}, Y shape: {y_test.shape}')\n","  \n","  emulator.model.eval()\n","\n","\n","  #--- Preprocessing ---\n","  # duplicate annual prediction\n","  if isDup: \n","    y_test = dupMonth(y_test, dup_idx=11)\n","\n","  age_mean = normData(tri_mean, y_mean, y_std)\n","  age_slope = normData(tri_slope, y_mean, y_std)\n","\n","  t_start = time.time()\n","  ls_rmse_all = []\n","  ls_pred_all = []\n","  for cur_age in tqdm(range(tri_age.size)):\n","\n","    # append init\n","    cur_x = addInitY2X(x_test, y_test[cur_age:cur_age+1])\n","    cur_x = cur_x[0]\n","    cur_y = y_test[cur_age,:,1:,-1]\n","    # logging.info(cur_x.shape, cur_y.shape) # (852, 40, 12, 143) (852, 40, 7)\n","\n","    # add age\n","    cur_x = addAgeTriplet_perAge(cur_x, tri_age[cur_age:(cur_age+1)], \n","                            age_mean[cur_age], age_slope[cur_age])\n","\n","    # predict\n","    ls_pred = []\n","    ls_rmse = []\n","    x_shape = cur_x.shape\n","    for i in range(x_shape[1]):\n","      tmp_x = cur_x[:,i].copy() # (B, 12, 158)\n","      tmp_y = cur_y[:,i].copy() # (B, 7)\n","      if i>0:\n","        if isPred2Input:\n","          # replace init tree height with prediction\n","          tmp_x[:,:,N_CONS:(N_CONS+N_OUT)] = np.repeat(ls_pred[-1][:,np.newaxis,:], N_T, axis=1)\n","      \n","      # use target only\n","      tmp_y = np.expand_dims(tmp_y, axis=1) # (B, 1, 7)\n","      tmp_y = np.concatenate([tmp_x[:, 0:1, 136:143], tmp_y], axis=1) # (B, 2, 7)\n","      tmp_x = tmp_x[:, :, :136] # (B, 12, 136)\n","      \n","      # # use age triplets\n","      # tmp_y = np.expand_dims(tmp_y, axis=1) # (B, 1, 7)\n","      # tmp_y1 = tmp_x[:, 0:1, 136:] # (batch*40, 1, 22)\n","      # tmp_y2 = np.concatenate([tmp_y, np.zeros((tmp_y.shape[0], 1, 15))], 2) # (batch*40, 1, 22)\n","      # tmp_y = np.concatenate([tmp_y1, tmp_y2], 1) # (batch*40, 2, 22)\n","      # tmp_x = tmp_x[:, :, :136] # (B, 12, 136)\n","          \n","      cur_pred, _ = emulator._process_one_batch(0, torch.tensor(tmp_x), torch.tensor(tmp_y))\n","      cur_pred = cur_pred.detach().cpu().numpy().squeeze()\n","  \n","      # post-processing\n","      zero_idx = invNormData(tmp_y[:,0,0],y_mean[0],y_std[0]) < 1\n","      # zero_idx = invNormData(cur_y[:,i,0],y_mean[0],y_std[0]) < 1\n","      cur_pred[zero_idx,0] = normData(np.array([0.],dtype=np.float32),y_mean[0],y_std[0])\n","\n","      # save\n","      ls_pred.append(cur_pred)\n","      ls_rmse.append(mean_squared_error(invNormData(cur_y[:,i],y_mean,y_std), \n","                                        invNormData(ls_pred[-1],y_mean,y_std), \n","                                        multioutput='raw_values', squared=False))\n","\n","    ls_rmse_all.append(np.array(ls_rmse))\n","    ls_pred_all.append(np.array(ls_pred))\n","    \n","    del cur_x, cur_y, tmp_x, cur_pred\n","    gc.collect()\n","    \n","  ls_rmse_all = np.array(ls_rmse_all)\n","  ls_pred_all = np.array(ls_pred_all)\n","  if isOutput:\n","    np.save(path_out+'_pred.npy', ls_pred_all)\n","\n","    pd_acc = convertRMSE2Table(ls_rmse_all, tri_age)\n","    pd_acc.to_csv(path_out+'_acc_details.csv', index=False)\n","  print('  Spent {:.1f} min for evaluation.\\n'.format((time.time()-t_start)/60))\n","  \n","  # plot age\n","  plotAge(ls_rmse_all, tri_age, isOutput, path_out, y_lim)\n","  \n","  return [y_test, ls_pred_all, ls_rmse_all]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dir_out = './results/' + setting +'/'\n","\n","_ = eval(exp, \n","  os.path.join(args.root_path, 'res_train4_test8_v02.npz'), \n","  dir_out+'test_pred', \n","  age_tri, data_stat, [age_start_idx,age_end_idx], \n","  isPred2Input=True, isTrain=False, isOutput=True, isDup=True, y_lim=[0,3.5])\n","\n","_ = eval(exp, \n","  os.path.join(args.root_path, 'res_train4_test8_v02.npz'), \n","  dir_out+'test_true', \n","  age_tri, data_stat, [age_start_idx,age_end_idx], \n","  isPred2Input=False, isTrain=False, isOutput=True, isDup=True, y_lim=[0,3.5])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1_X7O2BkFLvqyCdZzDZvV2MB0aAvYALLC","timestamp":1715868920678}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
